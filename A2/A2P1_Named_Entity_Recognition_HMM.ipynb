{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1sXm2wt519o"
      },
      "source": [
        "# Programming Problem 1: HMM for NER (30 points)\n",
        "Welcome to the programming portion of the assignment! Each assignment throughout the semester will have a written portion and a programming portion. We will be using [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true), so if you have never used it before, take a quick look through this introduction: [Working with Google Colab](https://docs.google.com/document/d/1LlnXoOblXwW3YX-0yG_5seTXJsb3kRdMMRYqs8Qqum4/edit?usp=sharing).\n",
        "\n",
        "### Writing Code\n",
        "Look for the keyword \"TODO\" and fill in your code in the empty space.\n",
        "Feel free to add and delete arguments in function signatures, but be careful that you might need to change them in function calls which are already present in the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEyk2ch1GYi0"
      },
      "source": [
        "### Data preprocessing\n",
        "\n",
        "In this section we will write code to load data and build the dataset for Named Entity Recognition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X_hx0PKdII9C",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import codecs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmssMqR2IKkC"
      },
      "source": [
        "Write a function to load sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q4MKd94oHDKr",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def zero_digits(s):\n",
        "    \"\"\"\n",
        "    Replace all digits in a string with zeros.\n",
        "    \"\"\"\n",
        "    return re.sub('\\d', '0', s)\n",
        "\n",
        "def load_sentences(path):\n",
        "    \"\"\"\n",
        "    Load sentences. A line must contain at least a word and its tag.\n",
        "    Sentences are separated by empty lines.\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in codecs.open(path, 'r', 'utf8'):\n",
        "        line = zero_digits(line.rstrip())\n",
        "        if not line:\n",
        "            if len(sentence) > 0:\n",
        "                if 'DOCSTART' not in sentence[0][0]:\n",
        "                    sentences.append(sentence)\n",
        "                sentence = []\n",
        "        else:\n",
        "            word = line.split()\n",
        "            assert len(word) >= 2\n",
        "            sentence.append(word)\n",
        "    if len(sentence) > 0:\n",
        "        if 'DOCSTART' not in sentence[0][0]:\n",
        "            sentences.append(sentence)\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example on the usage of zero_digits::\n",
        "text = \"My phone number is 123-456-7890.\"\n",
        "result = zero_digits(text)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCZHVpW7lxys",
        "outputId": "68741bb5-daa8-47db-f0bb-cfb07138c35c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My phone number is 000-000-0000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W76Clg4J2wo"
      },
      "source": [
        "Prepare the training/test data using the loaded sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1yS9JsVSMZ6l",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def create_dico(item_list):\n",
        "    \"\"\"\n",
        "    Create a dictionary of items from a list of list of items.\n",
        "    \"\"\"\n",
        "    assert type(item_list) is list\n",
        "    dico = {}\n",
        "    for items in item_list:\n",
        "        for item in items:\n",
        "            if item not in dico:\n",
        "                dico[item] = 1\n",
        "            else:\n",
        "                dico[item] += 1\n",
        "    return dico"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the create_dico function\n",
        "item_list = [\n",
        "    [\"apple\", \"banana\", \"apple\"],\n",
        "    [\"banana\", \"orange\"],\n",
        "    [\"apple\", \"orange\", \"banana\", \"banana\"]\n",
        "]\n",
        "\n",
        "dicto = create_dico(item_list)\n",
        "print(dicto)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AErGPy3LmyjY",
        "outputId": "f49d1d09-3ff3-4f12-cc43-89921f55a8fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'apple': 3, 'banana': 4, 'orange': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D_7t9tVCMdFY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def create_mapping(dico):\n",
        "    \"\"\"\n",
        "    Create a mapping (item to ID / ID to item) from a dictionary.\n",
        "    Items are ordered by decreasing frequency.\n",
        "    \"\"\"\n",
        "    sorted_items = sorted(dico.items(), key=lambda x: (-x[1], x[0]))\n",
        "    id_to_item = {i: v[0] for i, v in enumerate(sorted_items) if v[1] > 2}\n",
        "    item_to_id = {v: k for k, v in id_to_item.items()}\n",
        "    return item_to_id, id_to_item\n",
        "\n",
        "def word_mapping(sentences):\n",
        "    \"\"\"\n",
        "    Create a dictionary and a mapping of words, sorted by frequency.\n",
        "    \"\"\"\n",
        "    words = [[x[0] for x in s] for s in sentences]\n",
        "    dico = create_dico(words)\n",
        "    dico['<UNK>'] = 10000000\n",
        "    word_to_id, id_to_word = create_mapping(dico)\n",
        "    print(\"Found %i unique words (%i in total)\" % (\n",
        "        len(dico), sum(len(x) for x in words))\n",
        "    )\n",
        "    return dico, word_to_id, id_to_word\n",
        "\n",
        "def tag_mapping(sentences):\n",
        "    \"\"\"\n",
        "    Create a dictionary and a mapping of tags, sorted by frequency.\n",
        "    \"\"\"\n",
        "    tags = [[word[-1] for word in s] for s in sentences]\n",
        "    dico = create_dico(tags)\n",
        "    tag_to_id, id_to_tag = create_mapping(dico)\n",
        "    print(\"Found %i unique named entity tags\" % len(dico))\n",
        "    return dico, tag_to_id, id_to_tag"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sentence dataset (word-tag format)\n",
        "sentences = [\n",
        "    [[\"John\", \"B-PER\"], [\"loves\", \"O\"], [\"Mary\", \"B-PER\"]],\n",
        "    [[\"Paris\", \"B-LOC\"], [\"is\", \"O\"], [\"beautiful\", \"O\"]],\n",
        "    [[\"London\", \"B-LOC\"], [\"is\", \"O\"], [\"great\", \"O\"]],\n",
        "    [[\"John\", \"B-PER\"], [\"visits\", \"O\"], [\"London\", \"B-LOC\"]],\n",
        "]\n",
        "\n",
        "# Test word_mapping function\n",
        "dico_words, word_to_id, id_to_word = word_mapping(sentences)\n",
        "print(\"Word Dictionary:\", dico_words)\n",
        "print(\"Word to ID Mapping:\", word_to_id)\n",
        "print(\"ID to Word Mapping:\", id_to_word)\n",
        "\n",
        "# Test tag_mapping function\n",
        "dico_tags, tag_to_id, id_to_tag = tag_mapping(sentences)\n",
        "print(\"Tag Dictionary:\", dico_tags)\n",
        "print(\"Tag to ID Mapping:\", tag_to_id)\n",
        "print(\"ID to Tag Mapping:\", id_to_tag)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJDrI8DDnTt7",
        "outputId": "3e1089ad-8452-49ae-882c-825c9317e2b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10 unique words (12 in total)\n",
            "Word Dictionary: {'John': 2, 'loves': 1, 'Mary': 1, 'Paris': 1, 'is': 2, 'beautiful': 1, 'London': 2, 'great': 1, 'visits': 1, '<UNK>': 10000000}\n",
            "Word to ID Mapping: {'<UNK>': 0}\n",
            "ID to Word Mapping: {0: '<UNK>'}\n",
            "Found 3 unique named entity tags\n",
            "Tag Dictionary: {'B-PER': 3, 'O': 6, 'B-LOC': 3}\n",
            "Tag to ID Mapping: {'O': 0, 'B-LOC': 1, 'B-PER': 2}\n",
            "ID to Tag Mapping: {0: 'O', 1: 'B-LOC', 2: 'B-PER'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lNS57L87IQdT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(sentences, mode=None, word_to_id=None, tag_to_id=None):\n",
        "    \"\"\"\n",
        "    Prepare the dataset. Return 'data', which is a list of lists of dictionaries containing:\n",
        "        - words (strings)\n",
        "        - word indexes\n",
        "        - tag indexes\n",
        "    \"\"\"\n",
        "    assert mode == 'train' or (mode == 'test' and word_to_id and tag_to_id)\n",
        "\n",
        "    if mode=='train':\n",
        "        word_dic, word_to_id, id_to_word = word_mapping(sentences)\n",
        "        tag_dic, tag_to_id, id_to_tag = tag_mapping(sentences)\n",
        "\n",
        "    def f(x): return x\n",
        "    data = []\n",
        "    for s in sentences:\n",
        "        str_words = [w[0] for w in s]\n",
        "        words = [word_to_id[f(w) if f(w) in word_to_id else '<UNK>']\n",
        "                 for w in str_words]\n",
        "        tags = [tag_to_id[w[-1]] for w in s]\n",
        "        data.append({\n",
        "            'str_words': str_words,\n",
        "            'words': words,\n",
        "            'tags': tags,\n",
        "        })\n",
        "\n",
        "    if mode == 'train':\n",
        "        return data, {'word_to_id':word_to_id, 'id_to_word':id_to_word, 'tag_to_id':tag_to_id, 'id_to_tag':id_to_tag}\n",
        "    else:\n",
        "        return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgikvX-qKTL7"
      },
      "source": [
        "### Hidden Markov Model\n",
        "In this section, we will implement a bigram hidden markov model (HMM) that could perform two types of decoding: greedy decoding and viterbi decoding.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hidden Markov Model for Named Entity Recognition\n",
        "\n",
        "In this section, we implement a bigram Hidden Markov Model (HMM) for Named Entity Recognition. HMMs are probabilistic sequence models that capture the underlying structure of sequential data.\n",
        "\n",
        "### Components of HMM\n",
        "\n",
        "An HMM is defined by the following components:\n",
        "\n",
        "1. **States**: In our context, these are the named entity tags (e.g., O, PER, LOC, etc.)\n",
        "2. **Observations**: These are the words in our sentences\n",
        "3. **Three probability distributions**:\n",
        "\n",
        "#### 1. Initial probabilities: $\\pi_i = P(t_1 = i)$\n",
        "- The probability that the first tag in a sentence is tag $i$\n",
        "- Computed by counting how many times tag $i$ appears as the first tag in sentences in the training corpus, divided by the total number of sentences.\n",
        "- Formula: $\\pi_i = \\frac{\\text{Count of sentences starting with tag } i}{\\text{Total number of sentences}}$\n",
        "\n",
        "#### 2. Transition probabilities: $A_{i,j} = P(t_n = j | t_{n-1} = i)$\n",
        "- The probability of transitioning from tag $i$ to tag $j$\n",
        "- Computed by counting how many times tag $j$ follows tag $i$ in the training corpus, divided by the total number of times tag $i$ appears.\n",
        "- Formula: $A_{i,j} = \\frac{\\text{Count of tag } j \\text{ following tag } i}{\\text{Total occurrences of tag } i}$\n",
        "\n",
        "#### 3. Emission probabilities: $B_{i,k} = P(w_n = k | t_n = i)$\n",
        "- The probability of observing word $k$ given the tag $i$\n",
        "- Computed by counting how many times word $k$ is associated with tag $i$ in the training corpus, divided by the total number of times tag $i$ appears.\n",
        "- Formula: $B_{i,k} = \\frac{\\text{Count of word } k \\text{ with tag } i}{\\text{Total occurrences of tag } i}$\n",
        "\n",
        "### Decoding Algorithms\n",
        "\n",
        "We implement two decoding algorithms:\n",
        "\n",
        "#### 1. Greedy Decoding\n",
        "- For each position, choose the tag that maximizes the product of transition and emission probabilities\n",
        "- At position $n$, select tag $j$ that maximizes $A_{i,j} \\times B_{j,w_n}$ where $i$ is the tag at position $n-1$\n",
        "- Simple but doesn't guarantee the optimal sequence\n",
        "\n",
        "#### 2. Viterbi Decoding\n",
        "- Dynamic programming algorithm that finds the globally optimal tag sequence\n",
        "- Uses a matrix $M$ where $M[n,j]$ represents the probability of the most likely path ending with tag $j$ at position $n$\n",
        "- Recursive formula: $M[n,j] = \\max_i(M[n-1,i] \\times A_{i,j} \\times B_{j,w_n})$\n",
        "- Additionally, we use a backpointer matrix $B$ to reconstruct the optimal path\n",
        "- The final sequence is obtained by tracing back through the backpointer matrix from the most probable final state\n",
        "\n",
        "### Implementation Details\n",
        "\n",
        "- We use Maximum Likelihood Estimation (MLE) for training the model\n",
        "- To avoid numerical underflow issues in Viterbi, we work in the log space for probability calculations\n",
        "- The emission and transition probabilities are normalized to ensure they form valid probability distributions"
      ],
      "metadata": {
        "id": "q4fkJM4ArvRO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "te89fFIgLdFf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy import sparse\n",
        "import collections\n",
        "import codecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QCiZJCYKMln5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class HMM(object):\n",
        "    \"\"\"\n",
        "     HMM Model\n",
        "    \"\"\"\n",
        "    def __init__(self, dic, decode_type):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "        \"\"\"\n",
        "\n",
        "        self.num_words = len(dic['word_to_id'])\n",
        "        self.num_tags = len(dic['tag_to_id'])\n",
        "\n",
        "        self.initial_prob = np.ones([self.num_tags])\n",
        "        self.transition_prob = np.ones([self.num_tags, self.num_tags])\n",
        "        self.emission_prob = np.ones([self.num_tags, self.num_words])\n",
        "        self.decode_type = decode_type\n",
        "\n",
        "        return\n",
        "\n",
        "    def train(self, corpus):\n",
        "        \"\"\"\n",
        "        TODO: Train a bigram HMM model using MLE estimates.\n",
        "        Complete the code to compute self,initial_prob, self.transition_prob and self.emission_prob appropriately.\n",
        "\n",
        "        Args:\n",
        "            corpus is a list of dictionaries of the form:\n",
        "            {'str_words': str_words,   ### List of string words\n",
        "            'words': words,            ### List of word IDs\n",
        "            'tags': tags}              ### List of tag IDs\n",
        "            All three lists above have length equal to the sentence length for each instance.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Step 1: Compute initial_probs.\n",
        "        # initial_prob[x]: the probability of tag x to be assigned to the first token in a sentence.\n",
        "        self.initial_prob = np.zeros([self.num_tags])\n",
        "        for sentence in corpus:\n",
        "            # TODO: update self.initial_prob\n",
        "            # (5 points)\n",
        "            # START HERE\n",
        "            first_tag=sentence['tags'][0]\n",
        "            self.initial_prob[first_tag]+=1\n",
        "            # END HERE\n",
        "\n",
        "        # Normarlize initial_prob to sum to 1\n",
        "        self.initial_prob /= np.sum(self.initial_prob)\n",
        "\n",
        "        # Step 2: Complete the code to compute transition_prob.\n",
        "        # transition_prob[x][y]: the probability of tag y to appear after tag x.\n",
        "        self.transition_prob = np.zeros([self.num_tags, self.num_tags])\n",
        "        for sentence in corpus:\n",
        "            tag = sentence['tags']\n",
        "            for i in range(1, len(tag)):\n",
        "                # TODO: update self.transition_prob\n",
        "                # (5 points)\n",
        "                # START HERE\n",
        "                prev_tag = tag[i-1]\n",
        "                curr_tag = tag[i]\n",
        "                self.transition_prob[prev_tag][curr_tag] += 1\n",
        "                # END HERE\n",
        "\n",
        "        # Normalize every row of transition_prob to sum to 1.\n",
        "        for p in self.transition_prob:\n",
        "            p /= np.sum(p)\n",
        "\n",
        "\n",
        "        # Step 3: Complete the code to compute emission_prob\n",
        "        # emission_prob[x][y]: the probability of word y to appear given tag x.\n",
        "        # Note that for each sentence s in the corpus, word IDs are in s['words'].\n",
        "        self.emission_prob = np.zeros([self.num_tags, self.num_words])\n",
        "        for sentence in corpus:\n",
        "            for i in range(len(sentence['tags'])):\n",
        "                # TODO: update self.emission_prob\n",
        "                # (5 points)\n",
        "                # START HERE\n",
        "                tag_id = sentence['tags'][i]\n",
        "                word_id = sentence['words'][i]\n",
        "                self.emission_prob[tag_id][word_id] += 1\n",
        "                # END HERE\n",
        "\n",
        "        # For every tag, normalize the emission_prob to sum to 1.\n",
        "        for p in self.emission_prob:\n",
        "            p /= np.sum(p)\n",
        "\n",
        "        return\n",
        "\n",
        "    def greedy_decode(self, sentence):\n",
        "        \"\"\"\n",
        "        Decode a single sentence in Greedy fashion\n",
        "        Return a list of tags.\n",
        "        \"\"\"\n",
        "        tags = []\n",
        "\n",
        "        init_scores = [self.initial_prob[t] * self.emission_prob[t][sentence[0]] for t in range(self.num_tags)]\n",
        "        tags.append(np.argmax(init_scores))\n",
        "\n",
        "        for w in sentence[1:]:\n",
        "            scores = [self.transition_prob[tags[-1]][t] * self.emission_prob[t][w] for t in range(self.num_tags)]\n",
        "            tags.append(np.argmax(scores))\n",
        "\n",
        "        assert len(tags) == len(sentence)\n",
        "        return tags\n",
        "\n",
        "    def viterbi_decode(self, sentence):\n",
        "        \"\"\"\n",
        "        TODO: Complete the code to decode a single sentence using the Viterbi algorithm.\n",
        "        Args:\n",
        "             sentence -- a list of ints that represents word IDs.\n",
        "        Output:\n",
        "             tags     -- a list of ints that represents the tags decoded from the input.\n",
        "        \"\"\"\n",
        "        tags = []\n",
        "        l = len(sentence)\n",
        "\n",
        "        pi = self.initial_prob\n",
        "        A = self.transition_prob\n",
        "        O = self.emission_prob\n",
        "\n",
        "        # Let M be the state matrix.\n",
        "        # M[i,j]: most probable sequence of tags ending with tag j at the i-th token.\n",
        "        M = np.zeros((l, self.num_tags))\n",
        "        M[:,:] = float('-inf')\n",
        "\n",
        "        # Use B to track the path to reach the most probable sequence.\n",
        "        # B[i,j] is the tag of the (i-1)-th token in the most probable sequence ending with tag j at the i-th token.\n",
        "        B = np.zeros((l, self.num_tags), 'int')\n",
        "\n",
        "        # Compute the probability to assign each tag to the first token.\n",
        "        M[0, :] = pi * O[:, sentence[0]]\n",
        "\n",
        "        # Dynamic programming.\n",
        "        for i in range(1, l):\n",
        "            for j in range(self.num_tags):\n",
        "                # TODO: Compute M[i, j] and B[i, j].\n",
        "                # (10 points)\n",
        "                # START HERE\n",
        "                scores = M[i-1, :] + np.log(A[:, j]) + np.log(O[j, sentence[i]])\n",
        "                best_tag = np.argmax(scores)\n",
        "                M[i, j] = scores[best_tag]\n",
        "                B[i, j] = best_tag\n",
        "                # END HERE\n",
        "\n",
        "        # Extract the optimal sequence of tags from B.\n",
        "        # Start from the last position, and iteratively find the tag of each position that results in the most probable tag sequence.\n",
        "        tags.append(np.argmax(M[l-1,:]))\n",
        "        for i in range(l-1, 0, -1):\n",
        "            # TODO: Extract the tag of the (i-1)-th token that results in the most probable sequence of tags.\n",
        "            # (5 points)\n",
        "            # START HERE\n",
        "            prev_tag = B[i, tags[-1]]\n",
        "            tags.insert(0, prev_tag)\n",
        "            # END HERE\n",
        "\n",
        "        return tags\n",
        "\n",
        "    def tag(self, sentence):\n",
        "        \"\"\"\n",
        "        Tag a sentence using a trained HMM.\n",
        "        \"\"\"\n",
        "        if self.decode_type == 'viterbi':\n",
        "            return self.viterbi_decode(sentence)\n",
        "        elif self.decode_type == 'greedy':\n",
        "            return self.greedy_decode(sentence)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown decoding type\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6P0Qs5JM0x3"
      },
      "source": [
        "### Train and evaluate HMMs.\n",
        "This section contains driver code for learning a HMM for named entity recognition on a training corpus and evaluating it on a test corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DJRRLA2jOsl1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import codecs\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import collections\n",
        "from sklearn.metrics import f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk2KF59LOzSr"
      },
      "source": [
        "Write a function to tag the test corpus with a trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ldGSAHWSOwt1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def tag_corpus(model, test_corpus, output_file, dic):\n",
        "    if output_file:\n",
        "        f_output = codecs.open(output_file, 'w', 'utf-8')\n",
        "    start = time.time()\n",
        "\n",
        "    num_correct = 0.\n",
        "    num_total = 0.\n",
        "    y_pred=[]\n",
        "    y_actual=[]\n",
        "    print('Tagging...')\n",
        "    for i, sentence in enumerate(tqdm(test_corpus)):\n",
        "        tags = model.tag(sentence['words'])\n",
        "        str_tags = [dic['id_to_tag'][t] for t in tags]\n",
        "        y_pred.extend(tags)\n",
        "        y_actual.extend(sentence['tags'])\n",
        "\n",
        "        # Check accuracy.\n",
        "        num_correct += np.sum(np.array(tags) == np.array(sentence['tags']))\n",
        "        num_total += len([w for w in sentence['words']])\n",
        "\n",
        "        if output_file:\n",
        "            f_output.write('%s\\n' % ' '.join('%s%s%s' % (w, '__', y)\n",
        "                                             for w, y in zip(sentence['str_words'], str_tags)))\n",
        "\n",
        "    print('---- %i lines tagged in %.4fs ----' % (len(test_corpus), time.time() - start))\n",
        "    if output_file:\n",
        "        f_output.close()\n",
        "\n",
        "    print(\"Overall accuracy: %s\\n\" % (num_correct/num_total))\n",
        "    return y_pred,y_actual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhAjb7OuPEgT"
      },
      "source": [
        "Write a function a compute the confusion matrix and the F-1 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KC_VhUG0O98M",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def compute_score(y_pred,y_actual):\n",
        "    A = confusion_matrix(y_actual, y_pred)\n",
        "    f1 = f1_score(y_actual, y_pred,average=None)\n",
        "    print(\"Confusion Matrix:\\n\", A)\n",
        "    print(\"F-1 scores: \", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLFBiD4BPMl1"
      },
      "source": [
        "Write a function to train and evalute the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RFcYYThhPRbh",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def runHiddenMarkovModel(train_corpus,\n",
        "                         test_corpus,\n",
        "                         dic,\n",
        "                         decode_type,\n",
        "                         output_file):\n",
        "    # build and train the model\n",
        "    model = HMM(dic, decode_type)\n",
        "    model.train(train_corpus)\n",
        "\n",
        "    print(\"Train results:\")\n",
        "    pred, real = tag_corpus(model, train_corpus, output_file, dic)\n",
        "\n",
        "    print(\"Tags: \", dic['id_to_tag'])\n",
        "    A = compute_score(pred,real)\n",
        "\n",
        "    # test on validation\n",
        "    print(\"\\n-----------\\nTest results:\")\n",
        "    pred, real = tag_corpus(model, test_corpus, output_file, dic)\n",
        "\n",
        "    print(\"Tags: \", dic['id_to_tag'])\n",
        "    A = compute_score(pred,real)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vRsc-YrRAb2"
      },
      "source": [
        "### Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McZ9KpeQRlA9"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mjVwUkR9Rq53",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5009803b-fbb5-48c0-e23d-c5dc7a4d4315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-19 18:26:59--  https://princeton-nlp.github.io/cos484/assignments/a2/eng.train\n",
            "Resolving princeton-nlp.github.io (princeton-nlp.github.io)... 185.199.108.153, 185.199.111.153, 185.199.109.153, ...\n",
            "Connecting to princeton-nlp.github.io (princeton-nlp.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3213441 (3.1M) [application/octet-stream]\n",
            "Saving to: ‘eng.train’\n",
            "\n",
            "eng.train           100%[===================>]   3.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-03-19 18:27:00 (62.1 MB/s) - ‘eng.train’ saved [3213441/3213441]\n",
            "\n",
            "--2025-03-19 18:27:00--  https://princeton-nlp.github.io/cos484/assignments/a2/eng.val\n",
            "Resolving princeton-nlp.github.io (princeton-nlp.github.io)... 185.199.108.153, 185.199.111.153, 185.199.109.153, ...\n",
            "Connecting to princeton-nlp.github.io (princeton-nlp.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 774436 (756K) [application/octet-stream]\n",
            "Saving to: ‘eng.val’\n",
            "\n",
            "eng.val             100%[===================>] 756.29K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-03-19 18:27:00 (24.2 MB/s) - ‘eng.val’ saved [774436/774436]\n",
            "\n",
            "Found 20101 unique words (203621 in total)\n",
            "Found 5 unique named entity tags\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "!wget https://princeton-nlp.github.io/cos484/assignments/a2/eng.train\n",
        "!wget https://princeton-nlp.github.io/cos484/assignments/a2/eng.val\n",
        "\n",
        "train_file = 'eng.train'\n",
        "test_file = 'eng.val'\n",
        "\n",
        "# Load the training data\n",
        "train_sentences = load_sentences(train_file)\n",
        "train_corpus, dic = prepare_dataset(train_sentences, mode='train', word_to_id=None, tag_to_id=None)\n",
        "\n",
        "# Load the testing data\n",
        "test_sentences = load_sentences(test_file)\n",
        "test_corpus = prepare_dataset(test_sentences, mode='test', word_to_id=dic['word_to_id'], tag_to_id=dic['tag_to_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzNnUiBZS4ME"
      },
      "source": [
        "#### Experiment with an HMM with greedy decoding for Problem 2(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "h0t7W9JMTfLl",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555f4933-0521-4249-a1b3-b0343fcf8e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train results:\n",
            "Tagging...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14041/14041 [00:02<00:00, 6513.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 14041 lines tagged in 2.1585s ----\n",
            "Overall accuracy: 0.9544742438157164\n",
            "\n",
            "Tags:  {0: 'O', 1: 'PER', 2: 'ORG', 3: 'LOC', 4: 'MISC'}\n",
            "Confusion Matrix:\n",
            " [[168060    135   1233     48    102]\n",
            " [  1999   8628    456     39      6]\n",
            " [  1632     98   7291    731    273]\n",
            " [   741     49    567   6886     54]\n",
            " [   665     32    206    204   3486]]\n",
            "F-1 scores:  [0.98087109 0.85979073 0.73728385 0.84986115 0.81888654]\n",
            "\n",
            "-----------\n",
            "Test results:\n",
            "Tagging...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3490/3490 [00:00<00:00, 8092.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 3490 lines tagged in 0.4341s ----\n",
            "Overall accuracy: 0.9241331540561464\n",
            "\n",
            "Tags:  {0: 'O', 1: 'PER', 2: 'ORG', 3: 'LOC', 4: 'MISC'}\n",
            "Confusion Matrix:\n",
            " [[40558    17   543    17    29]\n",
            " [ 1105  1294   267    16     8]\n",
            " [  606    30  1382   176    56]\n",
            " [  249    15   215  1478    18]\n",
            " [  233     8    79    37   650]]\n",
            "F-1 scores:  [0.96664482 0.63838185 0.58361486 0.7991349  0.73529412]\n"
          ]
        }
      ],
      "source": [
        "runHiddenMarkovModel(\n",
        "    train_corpus = train_corpus,\n",
        "    test_corpus = test_corpus,\n",
        "    dic = dic,\n",
        "    decode_type = 'greedy',\n",
        "    output_file = None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP4iMShYX3Xp"
      },
      "source": [
        "#### Experiment with an HMM with viterbi decoding for Problem 2(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_zBEh-TpX8KC",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32f7590b-81c1-4a55-b224-c1caec5c4900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train results:\n",
            "Tagging...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/14041 [00:00<?, ?it/s]<ipython-input-11-c936f1159cc3>:137: RuntimeWarning: divide by zero encountered in log\n",
            "  scores = M[i-1, :] + np.log(A[:, j]) + np.log(O[j, sentence[i]])\n",
            "100%|██████████| 14041/14041 [00:07<00:00, 2002.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 14041 lines tagged in 7.0140s ----\n",
            "Overall accuracy: 0.9177540626949087\n",
            "\n",
            "Tags:  {0: 'O', 1: 'PER', 2: 'ORG', 3: 'LOC', 4: 'MISC'}\n",
            "Confusion Matrix:\n",
            " [[168440    724    275     26    113]\n",
            " [  4619   6412     62     29      6]\n",
            " [  4968    410   4169    332    146]\n",
            " [  2870     73    334   4972     48]\n",
            " [  1493     71     58     90   2881]]\n",
            "F-1 scores:  [0.95713247 0.68147518 0.55873484 0.72341045 0.7399512 ]\n",
            "\n",
            "-----------\n",
            "Test results:\n",
            "Tagging...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3490 [00:00<?, ?it/s]<ipython-input-11-c936f1159cc3>:137: RuntimeWarning: divide by zero encountered in log\n",
            "  scores = M[i-1, :] + np.log(A[:, j]) + np.log(O[j, sentence[i]])\n",
            "100%|██████████| 3490/3490 [00:01<00:00, 2297.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- 3490 lines tagged in 1.5208s ----\n",
            "Overall accuracy: 0.9096279998370207\n",
            "\n",
            "Tags:  {0: 'O', 1: 'PER', 2: 'ORG', 3: 'LOC', 4: 'MISC'}\n",
            "Confusion Matrix:\n",
            " [[40667   364    76    12    45]\n",
            " [ 1044  1593    33    13     7]\n",
            " [ 1280   101   726   104    39]\n",
            " [  708    29    77  1142    19]\n",
            " [  424    19    21    21   522]]\n",
            "F-1 scores:  [0.95365061 0.66430359 0.45617342 0.69911234 0.63697376]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "runHiddenMarkovModel(\n",
        "    train_corpus = train_corpus,\n",
        "    test_corpus = test_corpus,\n",
        "    dic = dic,\n",
        "    decode_type = 'viterbi',\n",
        "    output_file = None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def compare_decoding_methods(train_corpus, test_corpus, dic):\n",
        "    # Initialize models for both decoding methods\n",
        "    greedy_model = HMM(dic, 'greedy')\n",
        "    viterbi_model = HMM(dic, 'viterbi')\n",
        "\n",
        "    # Train both models\n",
        "    print(\"Training models...\")\n",
        "    greedy_model.train(train_corpus)\n",
        "    viterbi_model.train(train_corpus)\n",
        "\n",
        "    # Select a sample sentence from test corpus\n",
        "    sample_idx = 20  # You can change this to any index\n",
        "    sample = test_corpus[sample_idx]\n",
        "\n",
        "    # Get predictions from both models\n",
        "    greedy_tags = greedy_model.tag(sample['words'])\n",
        "    viterbi_tags = viterbi_model.tag(sample['words'])\n",
        "\n",
        "    # Convert tag IDs to tag names\n",
        "    greedy_str_tags = [dic['id_to_tag'][t] for t in greedy_tags]\n",
        "    viterbi_str_tags = [dic['id_to_tag'][t] for t in viterbi_tags]\n",
        "    true_str_tags = [dic['id_to_tag'][t] for t in sample['tags']]\n",
        "\n",
        "    # Create a pretty table to display results\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Word\", \"True Tag\", \"Greedy Prediction\", \"Viterbi Prediction\"]\n",
        "\n",
        "    # Add rows to the table\n",
        "    for i in range(len(sample['str_words'])):\n",
        "        word = sample['str_words'][i]\n",
        "        true_tag = true_str_tags[i]\n",
        "        greedy_tag = greedy_str_tags[i]\n",
        "        viterbi_tag = viterbi_str_tags[i]\n",
        "\n",
        "        # Highlight differences\n",
        "        if greedy_tag != true_tag and viterbi_tag == true_tag:\n",
        "            greedy_tag = f\"*{greedy_tag}*\"\n",
        "        elif viterbi_tag != true_tag and greedy_tag == true_tag:\n",
        "            viterbi_tag = f\"*{viterbi_tag}*\"\n",
        "        elif viterbi_tag != true_tag and greedy_tag != true_tag:\n",
        "            greedy_tag = f\"*{greedy_tag}*\"\n",
        "            viterbi_tag = f\"*{viterbi_tag}*\"\n",
        "\n",
        "        table.add_row([word, true_tag, greedy_tag, viterbi_tag])\n",
        "\n",
        "    # Print the table\n",
        "    print(\"\\nComparing Greedy vs Viterbi Decoding on a Sample Sentence:\")\n",
        "    print(table)\n",
        "\n",
        "    # Compute overall accuracy for both methods on test data\n",
        "    print(\"\\nComputing overall accuracy on test data...\")\n",
        "\n",
        "    # For greedy decoding\n",
        "    greedy_correct = 0\n",
        "    total_tokens = 0\n",
        "    for sentence in test_corpus:\n",
        "        tags = greedy_model.tag(sentence['words'])\n",
        "        greedy_correct += np.sum(np.array(tags) == np.array(sentence['tags']))\n",
        "        total_tokens += len(sentence['words'])\n",
        "\n",
        "    # For viterbi decoding\n",
        "    viterbi_correct = 0\n",
        "    for sentence in test_corpus:\n",
        "        tags = viterbi_model.tag(sentence['words'])\n",
        "        viterbi_correct += np.sum(np.array(tags) == np.array(sentence['tags']))\n",
        "\n",
        "    # Create accuracy comparison table\n",
        "    acc_table = PrettyTable()\n",
        "    acc_table.field_names = [\"Decoding Method\", \"Correct Predictions\", \"Total Tokens\", \"Accuracy\"]\n",
        "    acc_table.add_row([\"Greedy\", greedy_correct, total_tokens, f\"{greedy_correct/total_tokens:.4f}\"])\n",
        "    acc_table.add_row([\"Viterbi\", viterbi_correct, total_tokens, f\"{viterbi_correct/total_tokens:.4f}\"])\n",
        "\n",
        "    print(\"\\nOverall Accuracy Comparison:\")\n",
        "    print(acc_table)\n",
        "\n",
        "# Add this cell and run it after training both models\n",
        "compare_decoding_methods(train_corpus, test_corpus, dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk_1GT1aqQRY",
        "outputId": "09171e5b-49ac-4a81-b43f-9234081d8b92"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c936f1159cc3>:137: RuntimeWarning: divide by zero encountered in log\n",
            "  scores = M[i-1, :] + np.log(A[:, j]) + np.log(O[j, sentence[i]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparing Greedy vs Viterbi Decoding on a Sample Sentence:\n",
            "+----------------+----------+-------------------+--------------------+\n",
            "|      Word      | True Tag | Greedy Prediction | Viterbi Prediction |\n",
            "+----------------+----------+-------------------+--------------------+\n",
            "|    Somerset    |   ORG    |        ORG        |        *O*         |\n",
            "|       00       |    O     |         O         |         O          |\n",
            "|      and       |    O     |         O         |         O          |\n",
            "|      000       |    O     |         O         |         O          |\n",
            "|       (        |    O     |         O         |         O          |\n",
            "|       P.       |   PER    |        PER        |        *O*         |\n",
            "|    Simmons     |   PER    |        PER        |        PER         |\n",
            "|      0-00      |    O     |         O         |         O          |\n",
            "|       )        |    O     |         O         |         O          |\n",
            "|       ,        |    O     |         O         |         O          |\n",
            "| Leicestershire |   ORG    |        ORG        |        ORG         |\n",
            "|      000       |    O     |         O         |         O          |\n",
            "|       .        |    O     |         O         |         O          |\n",
            "+----------------+----------+-------------------+--------------------+\n",
            "\n",
            "Computing overall accuracy on test data...\n",
            "\n",
            "Overall Accuracy Comparison:\n",
            "+-----------------+---------------------+--------------+----------+\n",
            "| Decoding Method | Correct Predictions | Total Tokens | Accuracy |\n",
            "+-----------------+---------------------+--------------+----------+\n",
            "|      Greedy     |        45362        |    49086     |  0.9241  |\n",
            "|     Viterbi     |        44650        |    49086     |  0.9096  |\n",
            "+-----------------+---------------------+--------------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eoBgYMl7qiCY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}